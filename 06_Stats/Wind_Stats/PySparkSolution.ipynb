{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wind Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction:\n",
    "\n",
    "The data have been modified to contain some missing values, identified by NaN.  \n",
    "Using pandas should make this exercise\n",
    "easier, in particular for the bonus question.\n",
    "\n",
    "You should be able to perform all of these operations without using\n",
    "a for loop or other looping construct.\n",
    "\n",
    "\n",
    "1. The data in 'wind.data' has the following format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nYr Mo Dy   RPT   VAL   ROS   KIL   SHA   BIR   DUB   CLA   MUL   CLO   BEL   MAL\\n61  1  1 15.04 14.96 13.17  9.29   NaN  9.87 13.67 10.25 10.83 12.58 18.50 15.04\\n61  1  2 14.71   NaN 10.83  6.50 12.62  7.67 11.50 10.04  9.79  9.67 17.54 13.83\\n61  1  3 18.50 16.88 12.33 10.13 11.17  6.17 11.25   NaN  8.50  7.67 12.75 12.71\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Yr Mo Dy   RPT   VAL   ROS   KIL   SHA   BIR   DUB   CLA   MUL   CLO   BEL   MAL\n",
    "61  1  1 15.04 14.96 13.17  9.29   NaN  9.87 13.67 10.25 10.83 12.58 18.50 15.04\n",
    "61  1  2 14.71   NaN 10.83  6.50 12.62  7.67 11.50 10.04  9.79  9.67 17.54 13.83\n",
    "61  1  3 18.50 16.88 12.33 10.13 11.17  6.17 11.25   NaN  8.50  7.67 12.75 12.71\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   The first three columns are year, month and day.  The\n",
    "   remaining 12 columns are average windspeeds in knots at 12\n",
    "   locations in Ireland on that day.   \n",
    "\n",
    "   More information about the dataset go [here](wind.desc)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1. Import the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.1.20:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.1.2</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>winds</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x1251f9c70>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"winds\").getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2. Import the dataset from this [address](https://raw.githubusercontent.com/guipsamora/pandas_exercises/master/06_Stats/Wind_Stats/wind.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3. Assign it to a variable called data and replace the first 3 columns by a proper datetime index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkFiles\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Yr_Mo_Dy</th>\n",
       "      <th>RPT</th>\n",
       "      <th>VAL</th>\n",
       "      <th>ROS</th>\n",
       "      <th>KIL</th>\n",
       "      <th>SHA</th>\n",
       "      <th>BIR</th>\n",
       "      <th>DUB</th>\n",
       "      <th>CLA</th>\n",
       "      <th>MUL</th>\n",
       "      <th>CLO</th>\n",
       "      <th>BEL</th>\n",
       "      <th>MAL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2061-01-01</td>\n",
       "      <td>15.04</td>\n",
       "      <td>14.96</td>\n",
       "      <td>13.17</td>\n",
       "      <td>9.29</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.87</td>\n",
       "      <td>13.67</td>\n",
       "      <td>10.25</td>\n",
       "      <td>10.83</td>\n",
       "      <td>12.58</td>\n",
       "      <td>18.50</td>\n",
       "      <td>15.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2061-01-02</td>\n",
       "      <td>14.71</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.83</td>\n",
       "      <td>6.50</td>\n",
       "      <td>12.62</td>\n",
       "      <td>7.67</td>\n",
       "      <td>11.50</td>\n",
       "      <td>10.04</td>\n",
       "      <td>9.79</td>\n",
       "      <td>9.67</td>\n",
       "      <td>17.54</td>\n",
       "      <td>13.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2061-01-03</td>\n",
       "      <td>18.50</td>\n",
       "      <td>16.88</td>\n",
       "      <td>12.33</td>\n",
       "      <td>10.13</td>\n",
       "      <td>11.17</td>\n",
       "      <td>6.17</td>\n",
       "      <td>11.25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.50</td>\n",
       "      <td>7.67</td>\n",
       "      <td>12.75</td>\n",
       "      <td>12.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2061-01-04</td>\n",
       "      <td>10.58</td>\n",
       "      <td>6.63</td>\n",
       "      <td>11.75</td>\n",
       "      <td>4.58</td>\n",
       "      <td>4.54</td>\n",
       "      <td>2.88</td>\n",
       "      <td>8.63</td>\n",
       "      <td>1.79</td>\n",
       "      <td>5.83</td>\n",
       "      <td>5.88</td>\n",
       "      <td>5.46</td>\n",
       "      <td>10.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2061-01-05</td>\n",
       "      <td>13.33</td>\n",
       "      <td>13.25</td>\n",
       "      <td>11.42</td>\n",
       "      <td>6.17</td>\n",
       "      <td>10.71</td>\n",
       "      <td>8.21</td>\n",
       "      <td>11.92</td>\n",
       "      <td>6.54</td>\n",
       "      <td>10.92</td>\n",
       "      <td>10.34</td>\n",
       "      <td>12.92</td>\n",
       "      <td>11.83</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Yr_Mo_Dy    RPT    VAL    ROS    KIL    SHA   BIR    DUB    CLA    MUL  \\\n",
       "0 2061-01-01  15.04  14.96  13.17   9.29    NaN  9.87  13.67  10.25  10.83   \n",
       "1 2061-01-02  14.71    NaN  10.83   6.50  12.62  7.67  11.50  10.04   9.79   \n",
       "2 2061-01-03  18.50  16.88  12.33  10.13  11.17  6.17  11.25    NaN   8.50   \n",
       "3 2061-01-04  10.58   6.63  11.75   4.58   4.54  2.88   8.63   1.79   5.83   \n",
       "4 2061-01-05  13.33  13.25  11.42   6.17  10.71  8.21  11.92   6.54  10.92   \n",
       "\n",
       "     CLO    BEL    MAL  \n",
       "0  12.58  18.50  15.04  \n",
       "1   9.67  17.54  13.83  \n",
       "2   7.67  12.75  12.71  \n",
       "3   5.88   5.46  10.88  \n",
       "4  10.34  12.92  11.83  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# url = \"https://raw.githubusercontent.com/guipsamora/pandas_exercises/master/06_Stats/Wind_Stats/wind.data\"\n",
    "\n",
    "# spark.sparkContext.addFile(url)\n",
    "\n",
    "# data = spark.read.csv(SparkFiles.get(\"wind.data\"), header=True, inferSchema=True, sep=\" \")\n",
    "# produces null columns & null values in different columns\n",
    "\n",
    "data_url = 'https://raw.githubusercontent.com/guipsamora/pandas_exercises/master/06_Stats/Wind_Stats/wind.data'\n",
    "data = pd.read_csv(data_url, sep = \"\\s+\", parse_dates = [[0,1,2]]) \n",
    "# data = pd.read_csv(data_url, sep = \"\\s+\") \n",
    "data.head()\n",
    "\n",
    "# print(data.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6574"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df = spark.createDataFrame(data)\n",
    "data_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-----+-----+-----+-----+-----+----+-----+-----+-----+-----+-----+-----+\n",
      "|           Yr_Mo_Dy|  RPT|  VAL|  ROS|  KIL|  SHA| BIR|  DUB|  CLA|  MUL|  CLO|  BEL|  MAL|\n",
      "+-------------------+-----+-----+-----+-----+-----+----+-----+-----+-----+-----+-----+-----+\n",
      "|2061-01-01 00:00:00|15.04|14.96|13.17| 9.29|  NaN|9.87|13.67|10.25|10.83|12.58| 18.5|15.04|\n",
      "|2061-01-02 00:00:00|14.71|  NaN|10.83|  6.5|12.62|7.67| 11.5|10.04| 9.79| 9.67|17.54|13.83|\n",
      "|2061-01-03 00:00:00| 18.5|16.88|12.33|10.13|11.17|6.17|11.25|  NaN|  8.5| 7.67|12.75|12.71|\n",
      "|2061-01-04 00:00:00|10.58| 6.63|11.75| 4.58| 4.54|2.88| 8.63| 1.79| 5.83| 5.88| 5.46|10.88|\n",
      "|2061-01-05 00:00:00|13.33|13.25|11.42| 6.17|10.71|8.21|11.92| 6.54|10.92|10.34|12.92|11.83|\n",
      "+-------------------+-----+-----+-----+-----+-----+----+-----+-----+-----+-----+-----+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Yr_Mo_Dy: timestamp (nullable = true)\n",
      " |-- RPT: double (nullable = true)\n",
      " |-- VAL: double (nullable = true)\n",
      " |-- ROS: double (nullable = true)\n",
      " |-- KIL: double (nullable = true)\n",
      " |-- SHA: double (nullable = true)\n",
      " |-- BIR: double (nullable = true)\n",
      " |-- DUB: double (nullable = true)\n",
      " |-- CLA: double (nullable = true)\n",
      " |-- MUL: double (nullable = true)\n",
      " |-- CLO: double (nullable = true)\n",
      " |-- BEL: double (nullable = true)\n",
      " |-- MAL: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+-----+-----+-----+-----+----+-----+-----+-----+-----+-----+-----+\n",
      "|  Yr_Mo_Dy|  RPT|  VAL|  ROS|  KIL|  SHA| BIR|  DUB|  CLA|  MUL|  CLO|  BEL|  MAL|\n",
      "+----------+-----+-----+-----+-----+-----+----+-----+-----+-----+-----+-----+-----+\n",
      "|2061-01-01|15.04|14.96|13.17| 9.29|  NaN|9.87|13.67|10.25|10.83|12.58| 18.5|15.04|\n",
      "|2061-01-02|14.71|  NaN|10.83|  6.5|12.62|7.67| 11.5|10.04| 9.79| 9.67|17.54|13.83|\n",
      "|2061-01-03| 18.5|16.88|12.33|10.13|11.17|6.17|11.25|  NaN|  8.5| 7.67|12.75|12.71|\n",
      "|2061-01-04|10.58| 6.63|11.75| 4.58| 4.54|2.88| 8.63| 1.79| 5.83| 5.88| 5.46|10.88|\n",
      "|2061-01-05|13.33|13.25|11.42| 6.17|10.71|8.21|11.92| 6.54|10.92|10.34|12.92|11.83|\n",
      "+----------+-----+-----+-----+-----+-----+----+-----+-----+-----+-----+-----+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_df = data_df.withColumn(\"Yr_Mo_Dy\", to_date(\"Yr_Mo_Dy\"))\n",
    "data_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Yr_Mo_Dy: date (nullable = true)\n",
      " |-- RPT: double (nullable = true)\n",
      " |-- VAL: double (nullable = true)\n",
      " |-- ROS: double (nullable = true)\n",
      " |-- KIL: double (nullable = true)\n",
      " |-- SHA: double (nullable = true)\n",
      " |-- BIR: double (nullable = true)\n",
      " |-- DUB: double (nullable = true)\n",
      " |-- CLA: double (nullable = true)\n",
      " |-- MUL: double (nullable = true)\n",
      " |-- CLO: double (nullable = true)\n",
      " |-- BEL: double (nullable = true)\n",
      " |-- MAL: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4. Year 2061? Do we really have data from this year? Create a function to fix it and apply it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+-----+-----+-----+-----+----+-----+-----+-----+-----+-----+-----+----+---+---+\n",
      "|  Yr_Mo_Dy|  RPT|  VAL|  ROS|  KIL|  SHA| BIR|  DUB|  CLA|  MUL|  CLO|  BEL|  MAL|  Yr| Mo| Dy|\n",
      "+----------+-----+-----+-----+-----+-----+----+-----+-----+-----+-----+-----+-----+----+---+---+\n",
      "|2061-01-01|15.04|14.96|13.17| 9.29|  NaN|9.87|13.67|10.25|10.83|12.58| 18.5|15.04|2061|  1|  1|\n",
      "|2061-01-02|14.71|  NaN|10.83|  6.5|12.62|7.67| 11.5|10.04| 9.79| 9.67|17.54|13.83|2061|  1|  2|\n",
      "|2061-01-03| 18.5|16.88|12.33|10.13|11.17|6.17|11.25|  NaN|  8.5| 7.67|12.75|12.71|2061|  1|  3|\n",
      "|2061-01-04|10.58| 6.63|11.75| 4.58| 4.54|2.88| 8.63| 1.79| 5.83| 5.88| 5.46|10.88|2061|  1|  4|\n",
      "|2061-01-05|13.33|13.25|11.42| 6.17|10.71|8.21|11.92| 6.54|10.92|10.34|12.92|11.83|2061|  1|  5|\n",
      "+----------+-----+-----+-----+-----+-----+----+-----+-----+-----+-----+-----+-----+----+---+---+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "date_data_df = data_df.withColumn(\"Yr\", year(\"Yr_Mo_Dy\")) \\\n",
    ".withColumn(\"Mo\",month(\"Yr_Mo_Dy\")) \\\n",
    ".withColumn(\"Dy\", dayofmonth(\"Yr_Mo_Dy\"))\n",
    "\n",
    "date_data_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Yr_Mo_Dy: date (nullable = true)\n",
      " |-- RPT: double (nullable = true)\n",
      " |-- VAL: double (nullable = true)\n",
      " |-- ROS: double (nullable = true)\n",
      " |-- KIL: double (nullable = true)\n",
      " |-- SHA: double (nullable = true)\n",
      " |-- BIR: double (nullable = true)\n",
      " |-- DUB: double (nullable = true)\n",
      " |-- CLA: double (nullable = true)\n",
      " |-- MUL: double (nullable = true)\n",
      " |-- CLO: double (nullable = true)\n",
      " |-- BEL: double (nullable = true)\n",
      " |-- MAL: double (nullable = true)\n",
      " |-- Yr: integer (nullable = true)\n",
      " |-- Mo: integer (nullable = true)\n",
      " |-- Dy: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "date_data_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_century(x):\n",
    "    if x > 1989:\n",
    "        yr = x - 100 \n",
    "        return yr\n",
    "\n",
    "udf_fix_century = udf(lambda x: fix_century(x), IntegerType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+-----+-----+-----+-----+----+-----+-----+-----+-----+-----+-----+----+---+---+\n",
      "|  Yr_Mo_Dy|  RPT|  VAL|  ROS|  KIL|  SHA| BIR|  DUB|  CLA|  MUL|  CLO|  BEL|  MAL|  Yr| Mo| Dy|\n",
      "+----------+-----+-----+-----+-----+-----+----+-----+-----+-----+-----+-----+-----+----+---+---+\n",
      "|2061-01-01|15.04|14.96|13.17| 9.29|  NaN|9.87|13.67|10.25|10.83|12.58| 18.5|15.04|1961|  1|  1|\n",
      "|2061-01-02|14.71|  NaN|10.83|  6.5|12.62|7.67| 11.5|10.04| 9.79| 9.67|17.54|13.83|1961|  1|  2|\n",
      "|2061-01-03| 18.5|16.88|12.33|10.13|11.17|6.17|11.25|  NaN|  8.5| 7.67|12.75|12.71|1961|  1|  3|\n",
      "|2061-01-04|10.58| 6.63|11.75| 4.58| 4.54|2.88| 8.63| 1.79| 5.83| 5.88| 5.46|10.88|1961|  1|  4|\n",
      "|2061-01-05|13.33|13.25|11.42| 6.17|10.71|8.21|11.92| 6.54|10.92|10.34|12.92|11.83|1961|  1|  5|\n",
      "+----------+-----+-----+-----+-----+-----+----+-----+-----+-----+-----+-----+-----+----+---+---+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "date_data_df = date_data_df.withColumn(\"Yr\", udf_fix_century(col(\"Yr\")))\n",
    "date_data_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5. Set the right dates as the index. Pay attention at the data type, it should be datetime64[ns]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_drop = [\"Yr_Mo_Dy\",\"Yr\",\"Mo\",\"Dy\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+-----+-----+-----+-----+-----+----+-----+-----+-----+-----+-----+-----+----+---+---+\n",
      "|      Date|  Yr_Mo_Dy|  RPT|  VAL|  ROS|  KIL|  SHA| BIR|  DUB|  CLA|  MUL|  CLO|  BEL|  MAL|  Yr| Mo| Dy|\n",
      "+----------+----------+-----+-----+-----+-----+-----+----+-----+-----+-----+-----+-----+-----+----+---+---+\n",
      "|1961-01-01|2061-01-01|15.04|14.96|13.17| 9.29|  NaN|9.87|13.67|10.25|10.83|12.58| 18.5|15.04|1961|  1|  1|\n",
      "|1961-01-02|2061-01-02|14.71|  NaN|10.83|  6.5|12.62|7.67| 11.5|10.04| 9.79| 9.67|17.54|13.83|1961|  1|  2|\n",
      "|1961-01-03|2061-01-03| 18.5|16.88|12.33|10.13|11.17|6.17|11.25|  NaN|  8.5| 7.67|12.75|12.71|1961|  1|  3|\n",
      "|1961-01-04|2061-01-04|10.58| 6.63|11.75| 4.58| 4.54|2.88| 8.63| 1.79| 5.83| 5.88| 5.46|10.88|1961|  1|  4|\n",
      "|1961-01-05|2061-01-05|13.33|13.25|11.42| 6.17|10.71|8.21|11.92| 6.54|10.92|10.34|12.92|11.83|1961|  1|  5|\n",
      "+----------+----------+-----+-----+-----+-----+-----+----+-----+-----+-----+-----+-----+-----+----+---+---+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# d2_df = date_data_df.select(concat_ws(\"-\", date_data_df.Yr, date_data_df.Mo, date_data_df.Dy).\\\n",
    "#                             alias(\"Date\").cast(DateType()),*date_data_df.columns).drop(*cols_to_drop)\n",
    "\n",
    "d2_df = date_data_df.select(concat_ws(\"-\", date_data_df.Yr, date_data_df.Mo, date_data_df.Dy)\\\n",
    "                            .alias(\"Date\").cast(DateType()),*date_data_df.columns)\n",
    "\n",
    "d2_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Date: date (nullable = true)\n",
      " |-- Yr_Mo_Dy: date (nullable = true)\n",
      " |-- RPT: double (nullable = true)\n",
      " |-- VAL: double (nullable = true)\n",
      " |-- ROS: double (nullable = true)\n",
      " |-- KIL: double (nullable = true)\n",
      " |-- SHA: double (nullable = true)\n",
      " |-- BIR: double (nullable = true)\n",
      " |-- DUB: double (nullable = true)\n",
      " |-- CLA: double (nullable = true)\n",
      " |-- MUL: double (nullable = true)\n",
      " |-- CLO: double (nullable = true)\n",
      " |-- BEL: double (nullable = true)\n",
      " |-- MAL: double (nullable = true)\n",
      " |-- Yr: integer (nullable = true)\n",
      " |-- Mo: integer (nullable = true)\n",
      " |-- Dy: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "d2_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6. Compute how many values are missing for each location over the entire record.  \n",
    "#### They should be ignored in all calculations below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RPT',\n",
       " 'VAL',\n",
       " 'ROS',\n",
       " 'KIL',\n",
       " 'SHA',\n",
       " 'BIR',\n",
       " 'DUB',\n",
       " 'CLA',\n",
       " 'MUL',\n",
       " 'CLO',\n",
       " 'BEL',\n",
       " 'MAL',\n",
       " 'Yr',\n",
       " 'Mo',\n",
       " 'Dy']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = d2_df.columns\n",
    "cols.remove('Date')\n",
    "cols.remove('Yr_Mo_Dy')\n",
    "cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---+---+---+---+---+---+---+---+---+---+----+---+---+\n",
      "|RPT|VAL|ROS|KIL|SHA|BIR|DUB|CLA|MUL|CLO|BEL|MAL|  Yr| Mo| Dy|\n",
      "+---+---+---+---+---+---+---+---+---+---+---+---+----+---+---+\n",
      "|  6|  3|  2|  5|  2|  0|  3|  2|  3|  1|  0|  4|2922|  0|  0|\n",
      "+---+---+---+---+---+---+---+---+---+---+---+---+----+---+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "d2_df.select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in cols]).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+\n",
      "|RPT|VAL|ROS|KIL|SHA|BIR|DUB|CLA|MUL|CLO|BEL|MAL| Yr| Mo| Dy|\n",
      "+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+\n",
      "|  6|  3|  2|  5|  2|  0|  3|  2|  3|  1|  0|  4|  0|  0|  0|\n",
      "+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "d2_df.select([count(when(isnan(c), c)).alias(c) for c in cols]).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as F\n",
    "def count_missings(spark_df,sort=True):\n",
    "    \"\"\"\n",
    "    Counts number of nulls and nans in each column\n",
    "    \"\"\"\n",
    "    df = spark_df.select([F.count(F.when(F.isnan(c) | F.isnull(c), c)).alias(c) for (c,c_type) in spark_df.dtypes if c_type not in ('timestamp', 'string', 'date')]).toPandas()\n",
    "\n",
    "    if len(df) == 0:\n",
    "        print(\"There are no any missing values!\")\n",
    "        return None\n",
    "\n",
    "    if sort:\n",
    "        return df.rename(index={0: 'count'}).T.sort_values(\"count\",ascending=False)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Yr</th>\n",
       "      <td>2922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RPT</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KIL</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAL</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VAL</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DUB</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MUL</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ROS</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SHA</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CLA</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CLO</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BIR</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BEL</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mo</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dy</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     count\n",
       "Yr    2922\n",
       "RPT      6\n",
       "KIL      5\n",
       "MAL      4\n",
       "VAL      3\n",
       "DUB      3\n",
       "MUL      3\n",
       "ROS      2\n",
       "SHA      2\n",
       "CLA      2\n",
       "CLO      1\n",
       "BIR      0\n",
       "BEL      0\n",
       "Mo       0\n",
       "Dy       0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_counts = count_missings(d2_df)\n",
    "missing_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2953"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_counts['count'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7. Compute how many non-missing values there are in total."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "108805"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d2_df.count() * len(d2_df.columns) - missing_counts['count'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 8. Calculate the mean windspeeds of the windspeeds over all the locations and all the times.\n",
    "#### A single number for the entire dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trying to find an answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 9. Create a DataFrame called loc_stats and calculate the min, max and mean windspeeds and standard deviations of the windspeeds at each location over all the days \n",
    "\n",
    "#### A different set of numbers for each location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+------------------+------------------+-----------------+------------------+-----------------+------------------+-----------------+-----------------+-----------------+-----------------+-----------------+------------------+------------------+------------------+\n",
      "|summary|              RPT|               VAL|               ROS|              KIL|               SHA|              BIR|               DUB|              CLA|              MUL|              CLO|              BEL|              MAL|                Yr|                Mo|                Dy|\n",
      "+-------+-----------------+------------------+------------------+-----------------+------------------+-----------------+------------------+-----------------+-----------------+-----------------+-----------------+-----------------+------------------+------------------+------------------+\n",
      "|  count|             3624|              3624|              3624|             3624|              3624|             3624|              3624|             3624|             3624|             3624|             3624|             3624|              3624|              3624|              3624|\n",
      "|   mean|12.39243101545254|10.669381898454748|11.732461368653425|6.773170529801326|11.029908940397354|7.352317880794704|10.091600441501107|8.867356512141281|8.309144591611481|9.290543598233995|13.42682395143488|15.42613962472406|1965.5342163355408|6.5364238410596025|15.716059602649006|\n",
      "| stddev|5.636229672827054| 5.179758817931423| 5.143035880066034|3.729632615336292| 4.940767234338328|4.035774139321495| 5.098048468102159| 4.52570245843772|4.221687207544189|4.514680981369744|5.850352849968655|6.665473922744018|2.8570581801509847| 3.447936657845781|  8.79233891879864|\n",
      "|    min|             0.67|              0.37|              1.75|             0.08|              0.13|              0.0|              0.21|              0.0|             0.29|             0.04|             0.13|             0.67|              1961|                 1|                 1|\n",
      "|    max|             35.8|             33.37|             33.84|            28.46|             37.54|            26.16|             30.37|            31.08|            25.88|            28.21|            42.38|            42.54|              1970|                12|                31|\n",
      "+-------+-----------------+------------------+------------------+-----------------+------------------+-----------------+------------------+-----------------+-----------------+-----------------+-----------------+-----------------+------------------+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "loc_stats = d2_df.dropna().describe()\n",
    "\n",
    "# for c in loc_stats.columns:\n",
    "#     if loc_stats[c]\n",
    "#         loc_stats = loc_stats.withColumn(c, round(c, 2))\n",
    "    \n",
    "loc_stats.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 10. Create a DataFrame called day_stats and calculate the min, max and mean windspeed and standard deviations of the windspeeds across all the locations at each day.\n",
    "\n",
    "#### A different set of numbers for each day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+------------------+------------------+-----------------+------------------+-----------------+------------------+-----------------+-----------------+-----------------+-----------------+-----------------+------------------+------------------+------------------+\n",
      "|summary|              RPT|               VAL|               ROS|              KIL|               SHA|              BIR|               DUB|              CLA|              MUL|              CLO|              BEL|              MAL|                Yr|                Mo|                Dy|\n",
      "+-------+-----------------+------------------+------------------+-----------------+------------------+-----------------+------------------+-----------------+-----------------+-----------------+-----------------+-----------------+------------------+------------------+------------------+\n",
      "|  count|             3624|              3624|              3624|             3624|              3624|             3624|              3624|             3624|             3624|             3624|             3624|             3624|              3624|              3624|              3624|\n",
      "|   mean|12.39243101545254|10.669381898454748|11.732461368653425|6.773170529801326|11.029908940397354|7.352317880794704|10.091600441501107|8.867356512141281|8.309144591611481|9.290543598233995|13.42682395143488|15.42613962472406|1965.5342163355408|6.5364238410596025|15.716059602649006|\n",
      "| stddev|5.636229672827054| 5.179758817931423| 5.143035880066034|3.729632615336292| 4.940767234338328|4.035774139321495| 5.098048468102159| 4.52570245843772|4.221687207544189|4.514680981369744|5.850352849968655|6.665473922744018|2.8570581801509847| 3.447936657845781|  8.79233891879864|\n",
      "|    min|             0.67|              0.37|              1.75|             0.08|              0.13|              0.0|              0.21|              0.0|             0.29|             0.04|             0.13|             0.67|              1961|                 1|                 1|\n",
      "|    max|             35.8|             33.37|             33.84|            28.46|             37.54|            26.16|             30.37|            31.08|            25.88|            28.21|            42.38|            42.54|              1970|                12|                31|\n",
      "+-------+-----------------+------------------+------------------+-----------------+------------------+-----------------+------------------+-----------------+-----------------+-----------------+-----------------+-----------------+------------------+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "d2_df.dropna().describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 11. Find the average windspeed in January for each location.  \n",
    "#### Treat January 1961 and January 1962 both as January."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['RPT', 'VAL', 'ROS', 'KIL', 'SHA', 'BIR', 'DUB', 'CLA', 'MUL', 'CLO', 'BEL', 'MAL']\n"
     ]
    }
   ],
   "source": [
    "cols_to_show = d2_df.columns\n",
    "date_cols = ['Date','Yr_Mo_Dy','Yr','Mo','Dy']\n",
    "for i in date_cols:\n",
    "    cols_to_show.remove(i)\n",
    "print(cols_to_show)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RPT</th>\n",
       "      <th>VAL</th>\n",
       "      <th>ROS</th>\n",
       "      <th>KIL</th>\n",
       "      <th>SHA</th>\n",
       "      <th>BIR</th>\n",
       "      <th>DUB</th>\n",
       "      <th>CLA</th>\n",
       "      <th>MUL</th>\n",
       "      <th>CLO</th>\n",
       "      <th>BEL</th>\n",
       "      <th>MAL</th>\n",
       "      <th>Yr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.58</td>\n",
       "      <td>6.63</td>\n",
       "      <td>11.75</td>\n",
       "      <td>4.58</td>\n",
       "      <td>4.54</td>\n",
       "      <td>2.88</td>\n",
       "      <td>8.63</td>\n",
       "      <td>1.79</td>\n",
       "      <td>5.83</td>\n",
       "      <td>5.88</td>\n",
       "      <td>5.46</td>\n",
       "      <td>10.88</td>\n",
       "      <td>1961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.33</td>\n",
       "      <td>13.25</td>\n",
       "      <td>11.42</td>\n",
       "      <td>6.17</td>\n",
       "      <td>10.71</td>\n",
       "      <td>8.21</td>\n",
       "      <td>11.92</td>\n",
       "      <td>6.54</td>\n",
       "      <td>10.92</td>\n",
       "      <td>10.34</td>\n",
       "      <td>12.92</td>\n",
       "      <td>11.83</td>\n",
       "      <td>1961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13.21</td>\n",
       "      <td>8.12</td>\n",
       "      <td>9.96</td>\n",
       "      <td>6.67</td>\n",
       "      <td>5.37</td>\n",
       "      <td>4.50</td>\n",
       "      <td>10.67</td>\n",
       "      <td>4.42</td>\n",
       "      <td>7.17</td>\n",
       "      <td>7.50</td>\n",
       "      <td>8.12</td>\n",
       "      <td>13.17</td>\n",
       "      <td>1961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13.50</td>\n",
       "      <td>14.29</td>\n",
       "      <td>9.50</td>\n",
       "      <td>4.96</td>\n",
       "      <td>12.29</td>\n",
       "      <td>8.33</td>\n",
       "      <td>9.17</td>\n",
       "      <td>9.29</td>\n",
       "      <td>7.58</td>\n",
       "      <td>7.96</td>\n",
       "      <td>13.96</td>\n",
       "      <td>13.79</td>\n",
       "      <td>1961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.96</td>\n",
       "      <td>9.75</td>\n",
       "      <td>7.62</td>\n",
       "      <td>5.91</td>\n",
       "      <td>9.62</td>\n",
       "      <td>7.29</td>\n",
       "      <td>14.29</td>\n",
       "      <td>7.62</td>\n",
       "      <td>9.25</td>\n",
       "      <td>10.46</td>\n",
       "      <td>16.62</td>\n",
       "      <td>16.46</td>\n",
       "      <td>1961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>10.54</td>\n",
       "      <td>19.08</td>\n",
       "      <td>7.83</td>\n",
       "      <td>3.17</td>\n",
       "      <td>10.00</td>\n",
       "      <td>7.00</td>\n",
       "      <td>5.17</td>\n",
       "      <td>8.79</td>\n",
       "      <td>5.21</td>\n",
       "      <td>2.88</td>\n",
       "      <td>12.42</td>\n",
       "      <td>9.96</td>\n",
       "      <td>1970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>17.50</td>\n",
       "      <td>17.67</td>\n",
       "      <td>17.83</td>\n",
       "      <td>8.58</td>\n",
       "      <td>17.37</td>\n",
       "      <td>14.62</td>\n",
       "      <td>13.75</td>\n",
       "      <td>14.88</td>\n",
       "      <td>11.42</td>\n",
       "      <td>12.50</td>\n",
       "      <td>18.79</td>\n",
       "      <td>21.25</td>\n",
       "      <td>1970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>12.96</td>\n",
       "      <td>11.08</td>\n",
       "      <td>18.12</td>\n",
       "      <td>6.83</td>\n",
       "      <td>9.83</td>\n",
       "      <td>9.46</td>\n",
       "      <td>10.83</td>\n",
       "      <td>10.63</td>\n",
       "      <td>10.17</td>\n",
       "      <td>8.58</td>\n",
       "      <td>10.58</td>\n",
       "      <td>19.00</td>\n",
       "      <td>1970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>9.79</td>\n",
       "      <td>6.63</td>\n",
       "      <td>14.96</td>\n",
       "      <td>3.17</td>\n",
       "      <td>5.54</td>\n",
       "      <td>3.21</td>\n",
       "      <td>5.66</td>\n",
       "      <td>2.79</td>\n",
       "      <td>2.67</td>\n",
       "      <td>2.17</td>\n",
       "      <td>4.50</td>\n",
       "      <td>8.54</td>\n",
       "      <td>1970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>22.46</td>\n",
       "      <td>21.50</td>\n",
       "      <td>20.91</td>\n",
       "      <td>12.96</td>\n",
       "      <td>19.33</td>\n",
       "      <td>15.67</td>\n",
       "      <td>17.54</td>\n",
       "      <td>15.25</td>\n",
       "      <td>15.46</td>\n",
       "      <td>14.46</td>\n",
       "      <td>21.96</td>\n",
       "      <td>26.83</td>\n",
       "      <td>1970</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>305 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       RPT    VAL    ROS    KIL    SHA    BIR    DUB    CLA    MUL    CLO  \\\n",
       "0    10.58   6.63  11.75   4.58   4.54   2.88   8.63   1.79   5.83   5.88   \n",
       "1    13.33  13.25  11.42   6.17  10.71   8.21  11.92   6.54  10.92  10.34   \n",
       "2    13.21   8.12   9.96   6.67   5.37   4.50  10.67   4.42   7.17   7.50   \n",
       "3    13.50  14.29   9.50   4.96  12.29   8.33   9.17   9.29   7.58   7.96   \n",
       "4    10.96   9.75   7.62   5.91   9.62   7.29  14.29   7.62   9.25  10.46   \n",
       "..     ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "300  10.54  19.08   7.83   3.17  10.00   7.00   5.17   8.79   5.21   2.88   \n",
       "301  17.50  17.67  17.83   8.58  17.37  14.62  13.75  14.88  11.42  12.50   \n",
       "302  12.96  11.08  18.12   6.83   9.83   9.46  10.83  10.63  10.17   8.58   \n",
       "303   9.79   6.63  14.96   3.17   5.54   3.21   5.66   2.79   2.67   2.17   \n",
       "304  22.46  21.50  20.91  12.96  19.33  15.67  17.54  15.25  15.46  14.46   \n",
       "\n",
       "       BEL    MAL    Yr  \n",
       "0     5.46  10.88  1961  \n",
       "1    12.92  11.83  1961  \n",
       "2     8.12  13.17  1961  \n",
       "3    13.96  13.79  1961  \n",
       "4    16.62  16.46  1961  \n",
       "..     ...    ...   ...  \n",
       "300  12.42   9.96  1970  \n",
       "301  18.79  21.25  1970  \n",
       "302  10.58  19.00  1970  \n",
       "303   4.50   8.54  1970  \n",
       "304  21.96  26.83  1970  \n",
       "\n",
       "[305 rows x 13 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d2_mean = d2_df.filter(d2_df.Mo.isin(1)).select(*cols_to_show).dropna().toPandas()\n",
    "d2_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(d2_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RPT      14.280656\n",
       "VAL      12.449016\n",
       "ROS      13.117049\n",
       "KIL       7.224393\n",
       "SHA      11.464131\n",
       "BIR       7.777672\n",
       "DUB      11.509410\n",
       "CLA       9.355934\n",
       "MUL       8.529377\n",
       "CLO       9.913607\n",
       "BEL      14.000951\n",
       "MAL      16.716754\n",
       "Yr     1965.573770\n",
       "dtype: float64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d2_mean.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 12. Downsample the record to a yearly frequency for each location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['RPT', 'VAL', 'ROS', 'KIL', 'SHA', 'BIR', 'DUB', 'CLA', 'MUL', 'CLO', 'BEL', 'MAL', 'Yr']\n"
     ]
    }
   ],
   "source": [
    "cols_to_show.append('Yr')\n",
    "print(cols_to_show)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------------------+------------------+------------------+-----------------+------------------+-----------------+------------------+------------------+-----------------+------------------+------------------+------------------+-------+\n",
      "|  Yr|          avg(RPT)|          avg(VAL)|          avg(ROS)|         avg(KIL)|          avg(SHA)|         avg(BIR)|          avg(DUB)|          avg(CLA)|         avg(MUL)|          avg(CLO)|          avg(BEL)|          avg(MAL)|avg(Yr)|\n",
      "+----+------------------+------------------+------------------+-----------------+------------------+-----------------+------------------+------------------+-----------------+------------------+------------------+------------------+-------+\n",
      "|1961| 12.20758823529412|10.207205882352943|11.282852941176477|6.846441176470588|10.742735294117647|7.617147058823529| 9.633264705882354| 8.684911764705886|8.571941176470586| 9.700470588235298|13.271558823529414|13.587205882352938| 1961.0|\n",
      "|1962|12.274779005524865|10.150856353591157|11.714364640883984|6.964337016574588|10.692265193370169|7.415331491712711|11.043121546961332| 8.829806629834257|8.335552486187844| 9.693812154696131| 12.98569060773481|14.361436464088401| 1962.0|\n",
      "|1963|12.813452054794523|10.836986301369864|12.541150684931509| 7.33005479452055|11.724109589041097|8.434712328767121|11.075698630136985|10.336547945205478|8.903589041095888|10.224438356164384|13.638876712328768|14.999013698630135| 1963.0|\n",
      "|1964|12.363661202185794| 10.92016393442623| 12.10437158469945|6.787786885245901| 11.45448087431694|7.570874316939892|10.259153005464482| 9.467349726775955|7.789016393442626| 10.20795081967213|13.740546448087432|14.910300546448083| 1964.0|\n",
      "|1965|12.451369863013696|11.075534246575344|11.848767123287669|6.858465753424656|11.024794520547943|7.478109589041094|10.618712328767126| 8.879917808219176|7.907424657534249| 9.918082191780817|12.964246575342463| 15.59164383561644| 1965.0|\n",
      "+----+------------------+------------------+------------------+-----------------+------------------+-----------------+------------------+------------------+-----------------+------------------+------------------+------------------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "d2_year_avg = d2_df.select(*cols_to_show).dropna().groupBy('Yr').avg().orderBy('Yr')\n",
    "d2_year_avg.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Yr</th>\n",
       "      <th>avg(RPT)</th>\n",
       "      <th>avg(VAL)</th>\n",
       "      <th>avg(ROS)</th>\n",
       "      <th>avg(KIL)</th>\n",
       "      <th>avg(SHA)</th>\n",
       "      <th>avg(BIR)</th>\n",
       "      <th>avg(DUB)</th>\n",
       "      <th>avg(CLA)</th>\n",
       "      <th>avg(MUL)</th>\n",
       "      <th>avg(CLO)</th>\n",
       "      <th>avg(BEL)</th>\n",
       "      <th>avg(MAL)</th>\n",
       "      <th>avg(Yr)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1961</td>\n",
       "      <td>12.207588</td>\n",
       "      <td>10.207206</td>\n",
       "      <td>11.282853</td>\n",
       "      <td>6.846441</td>\n",
       "      <td>10.742735</td>\n",
       "      <td>7.617147</td>\n",
       "      <td>9.633265</td>\n",
       "      <td>8.684912</td>\n",
       "      <td>8.571941</td>\n",
       "      <td>9.700471</td>\n",
       "      <td>13.271559</td>\n",
       "      <td>13.587206</td>\n",
       "      <td>1961.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1962</td>\n",
       "      <td>12.274779</td>\n",
       "      <td>10.150856</td>\n",
       "      <td>11.714365</td>\n",
       "      <td>6.964337</td>\n",
       "      <td>10.692265</td>\n",
       "      <td>7.415331</td>\n",
       "      <td>11.043122</td>\n",
       "      <td>8.829807</td>\n",
       "      <td>8.335552</td>\n",
       "      <td>9.693812</td>\n",
       "      <td>12.985691</td>\n",
       "      <td>14.361436</td>\n",
       "      <td>1962.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1963</td>\n",
       "      <td>12.813452</td>\n",
       "      <td>10.836986</td>\n",
       "      <td>12.541151</td>\n",
       "      <td>7.330055</td>\n",
       "      <td>11.724110</td>\n",
       "      <td>8.434712</td>\n",
       "      <td>11.075699</td>\n",
       "      <td>10.336548</td>\n",
       "      <td>8.903589</td>\n",
       "      <td>10.224438</td>\n",
       "      <td>13.638877</td>\n",
       "      <td>14.999014</td>\n",
       "      <td>1963.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1964</td>\n",
       "      <td>12.363661</td>\n",
       "      <td>10.920164</td>\n",
       "      <td>12.104372</td>\n",
       "      <td>6.787787</td>\n",
       "      <td>11.454481</td>\n",
       "      <td>7.570874</td>\n",
       "      <td>10.259153</td>\n",
       "      <td>9.467350</td>\n",
       "      <td>7.789016</td>\n",
       "      <td>10.207951</td>\n",
       "      <td>13.740546</td>\n",
       "      <td>14.910301</td>\n",
       "      <td>1964.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1965</td>\n",
       "      <td>12.451370</td>\n",
       "      <td>11.075534</td>\n",
       "      <td>11.848767</td>\n",
       "      <td>6.858466</td>\n",
       "      <td>11.024795</td>\n",
       "      <td>7.478110</td>\n",
       "      <td>10.618712</td>\n",
       "      <td>8.879918</td>\n",
       "      <td>7.907425</td>\n",
       "      <td>9.918082</td>\n",
       "      <td>12.964247</td>\n",
       "      <td>15.591644</td>\n",
       "      <td>1965.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1966</td>\n",
       "      <td>13.461973</td>\n",
       "      <td>11.557205</td>\n",
       "      <td>12.020630</td>\n",
       "      <td>7.345726</td>\n",
       "      <td>11.805041</td>\n",
       "      <td>7.793671</td>\n",
       "      <td>10.579808</td>\n",
       "      <td>8.835096</td>\n",
       "      <td>8.514438</td>\n",
       "      <td>9.768959</td>\n",
       "      <td>14.265836</td>\n",
       "      <td>16.307260</td>\n",
       "      <td>1966.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1967</td>\n",
       "      <td>12.737151</td>\n",
       "      <td>10.990986</td>\n",
       "      <td>11.739397</td>\n",
       "      <td>7.143425</td>\n",
       "      <td>11.630740</td>\n",
       "      <td>7.368164</td>\n",
       "      <td>10.652027</td>\n",
       "      <td>9.325616</td>\n",
       "      <td>8.645014</td>\n",
       "      <td>9.547425</td>\n",
       "      <td>14.774548</td>\n",
       "      <td>17.135945</td>\n",
       "      <td>1967.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1968</td>\n",
       "      <td>11.835628</td>\n",
       "      <td>10.468197</td>\n",
       "      <td>11.409754</td>\n",
       "      <td>6.477678</td>\n",
       "      <td>10.760765</td>\n",
       "      <td>6.067322</td>\n",
       "      <td>8.859180</td>\n",
       "      <td>8.255519</td>\n",
       "      <td>7.224945</td>\n",
       "      <td>7.832978</td>\n",
       "      <td>12.808634</td>\n",
       "      <td>15.017486</td>\n",
       "      <td>1968.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1969</td>\n",
       "      <td>11.166356</td>\n",
       "      <td>9.723699</td>\n",
       "      <td>10.902000</td>\n",
       "      <td>5.767973</td>\n",
       "      <td>9.873918</td>\n",
       "      <td>6.189973</td>\n",
       "      <td>8.564493</td>\n",
       "      <td>7.711397</td>\n",
       "      <td>7.924521</td>\n",
       "      <td>7.754384</td>\n",
       "      <td>12.621233</td>\n",
       "      <td>15.762904</td>\n",
       "      <td>1969.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1970</td>\n",
       "      <td>12.600329</td>\n",
       "      <td>10.726932</td>\n",
       "      <td>11.730247</td>\n",
       "      <td>6.217178</td>\n",
       "      <td>10.567370</td>\n",
       "      <td>7.609452</td>\n",
       "      <td>9.609890</td>\n",
       "      <td>8.334630</td>\n",
       "      <td>9.297616</td>\n",
       "      <td>8.289808</td>\n",
       "      <td>13.183644</td>\n",
       "      <td>16.456027</td>\n",
       "      <td>1970.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Yr   avg(RPT)   avg(VAL)   avg(ROS)  avg(KIL)   avg(SHA)  avg(BIR)  \\\n",
       "0  1961  12.207588  10.207206  11.282853  6.846441  10.742735  7.617147   \n",
       "1  1962  12.274779  10.150856  11.714365  6.964337  10.692265  7.415331   \n",
       "2  1963  12.813452  10.836986  12.541151  7.330055  11.724110  8.434712   \n",
       "3  1964  12.363661  10.920164  12.104372  6.787787  11.454481  7.570874   \n",
       "4  1965  12.451370  11.075534  11.848767  6.858466  11.024795  7.478110   \n",
       "5  1966  13.461973  11.557205  12.020630  7.345726  11.805041  7.793671   \n",
       "6  1967  12.737151  10.990986  11.739397  7.143425  11.630740  7.368164   \n",
       "7  1968  11.835628  10.468197  11.409754  6.477678  10.760765  6.067322   \n",
       "8  1969  11.166356   9.723699  10.902000  5.767973   9.873918  6.189973   \n",
       "9  1970  12.600329  10.726932  11.730247  6.217178  10.567370  7.609452   \n",
       "\n",
       "    avg(DUB)   avg(CLA)  avg(MUL)   avg(CLO)   avg(BEL)   avg(MAL)  avg(Yr)  \n",
       "0   9.633265   8.684912  8.571941   9.700471  13.271559  13.587206   1961.0  \n",
       "1  11.043122   8.829807  8.335552   9.693812  12.985691  14.361436   1962.0  \n",
       "2  11.075699  10.336548  8.903589  10.224438  13.638877  14.999014   1963.0  \n",
       "3  10.259153   9.467350  7.789016  10.207951  13.740546  14.910301   1964.0  \n",
       "4  10.618712   8.879918  7.907425   9.918082  12.964247  15.591644   1965.0  \n",
       "5  10.579808   8.835096  8.514438   9.768959  14.265836  16.307260   1966.0  \n",
       "6  10.652027   9.325616  8.645014   9.547425  14.774548  17.135945   1967.0  \n",
       "7   8.859180   8.255519  7.224945   7.832978  12.808634  15.017486   1968.0  \n",
       "8   8.564493   7.711397  7.924521   7.754384  12.621233  15.762904   1969.0  \n",
       "9   9.609890   8.334630  9.297616   8.289808  13.183644  16.456027   1970.0  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d2_year_avg.toPandas() #just to have a beautiful output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 13. Downsample the record to a monthly frequency for each location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['RPT', 'VAL', 'ROS', 'KIL', 'SHA', 'BIR', 'DUB', 'CLA', 'MUL', 'CLO', 'BEL', 'MAL', 'Yr']\n"
     ]
    }
   ],
   "source": [
    "print(cols_to_show)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_show.remove('Yr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['RPT', 'VAL', 'ROS', 'KIL', 'SHA', 'BIR', 'DUB', 'CLA', 'MUL', 'CLO', 'BEL', 'MAL', 'Mo', 'Yr']\n"
     ]
    }
   ],
   "source": [
    "# cols_to_show.append('Mo')\n",
    "# cols_to_show.append('Yr')\n",
    "print(cols_to_show)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# d2_month_avg = d2_df.filter(d2_df.Yr.isin(1961)).select(*cols_to_show).dropna().groupBy('Mo').avg().orderBy('Mo')\n",
    "# d2_month_avg.show()\n",
    "\n",
    "#trying to find an easier way"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 14. Downsample the record to a weekly frequency for each location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trying to find an answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 15. Calculate the min, max and mean windspeeds and standard deviations of the windspeeds across all locations for each week (assume that the first week starts on January 2 1961) for the first 52 weeks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Date',\n",
       " 'Yr_Mo_Dy',\n",
       " 'RPT',\n",
       " 'VAL',\n",
       " 'ROS',\n",
       " 'KIL',\n",
       " 'SHA',\n",
       " 'BIR',\n",
       " 'DUB',\n",
       " 'CLA',\n",
       " 'MUL',\n",
       " 'CLO',\n",
       " 'BEL',\n",
       " 'MAL',\n",
       " 'Yr',\n",
       " 'Mo',\n",
       " 'Dy']"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d2_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+-----+-----+-----+----+-----+----+-----+-----+-----+-----+-----+-----+----+---+---+\n",
      "|      Date|  Yr_Mo_Dy|  RPT|  VAL|  ROS| KIL|  SHA| BIR|  DUB|  CLA|  MUL|  CLO|  BEL|  MAL|  Yr| Mo| Dy|\n",
      "+----------+----------+-----+-----+-----+----+-----+----+-----+-----+-----+-----+-----+-----+----+---+---+\n",
      "|1961-01-01|2061-01-01|15.04|14.96|13.17|9.29|  NaN|9.87|13.67|10.25|10.83|12.58| 18.5|15.04|1961|  1|  1|\n",
      "|1961-01-02|2061-01-02|14.71|  NaN|10.83| 6.5|12.62|7.67| 11.5|10.04| 9.79| 9.67|17.54|13.83|1961|  1|  2|\n",
      "+----------+----------+-----+-----+-----+----+-----+----+-----+-----+-----+-----+-----+-----+----+---+---+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "d2_df.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+-----+-----+-----+----+-----+----+-----+-----+-----+-----+-----+-----+----+---+---+---+\n",
      "|      Date|  Yr_Mo_Dy|  RPT|  VAL|  ROS| KIL|  SHA| BIR|  DUB|  CLA|  MUL|  CLO|  BEL|  MAL|  Yr| Mo| Dy| Wk|\n",
      "+----------+----------+-----+-----+-----+----+-----+----+-----+-----+-----+-----+-----+-----+----+---+---+---+\n",
      "|1961-01-01|2061-01-01|15.04|14.96|13.17|9.29|  NaN|9.87|13.67|10.25|10.83|12.58| 18.5|15.04|1961|  1|  1| 52|\n",
      "|1961-01-02|2061-01-02|14.71|  NaN|10.83| 6.5|12.62|7.67| 11.5|10.04| 9.79| 9.67|17.54|13.83|1961|  1|  2|  1|\n",
      "+----------+----------+-----+-----+-----+----+-----+----+-----+-----+-----+-----+-----+-----+----+---+---+---+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "d2_wk_df = d2_df.withColumn('Wk', weekofyear(\"Date\"))\n",
    "d2_wk_df.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['RPT', 'VAL', 'ROS', 'KIL', 'SHA', 'BIR', 'DUB', 'CLA', 'MUL', 'CLO', 'BEL', 'MAL', 'Mo', 'Yr']\n"
     ]
    }
   ],
   "source": [
    "print(cols_to_show)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_show.append('Wk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------------------+-----------------+------------------+-----------------+-----------------+-----------------+-----------------+-----------------+-----------------+-----------------+------------------+------------------+-------+-------+-------+\n",
      "| Wk|          avg(RPT)|         avg(VAL)|          avg(ROS)|         avg(KIL)|         avg(SHA)|         avg(BIR)|         avg(DUB)|         avg(CLA)|         avg(MUL)|         avg(CLO)|          avg(BEL)|          avg(MAL)|avg(Mo)|avg(Yr)|avg(Wk)|\n",
      "+---+------------------+-----------------+------------------+-----------------+-----------------+-----------------+-----------------+-----------------+-----------------+-----------------+------------------+------------------+-------+-------+-------+\n",
      "|  1|            12.316|           10.408|             10.05|            5.658|8.505999999999998|            6.242|           10.936|            5.932|             8.15|            8.428|            11.416|13.225999999999999|    1.0| 1961.0|    1.0|\n",
      "|  2|12.468571428571428|8.967142857142857|11.958571428571428|4.630000000000001|7.351428571428571|5.072857142857144|7.535714285714286|6.819999999999999|5.712857142857142|7.571428571428571|11.125714285714286|11.024285714285716|    1.0| 1961.0|    2.0|\n",
      "+---+------------------+-----------------+------------------+-----------------+-----------------+-----------------+-----------------+-----------------+-----------------+-----------------+------------------+------------------+-------+-------+-------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "d2_wk_avg_1961 = d2_wk_df.filter(d2_wk_df.Yr.isin(1961)).select(*cols_to_show).dropna().groupBy('Wk').avg().orderBy('Wk')\n",
    "d2_wk_avg_1961.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+-------+-------+-------+\n",
      "| Wk|min(RPT)|min(VAL)|min(ROS)|min(KIL)|min(SHA)|min(BIR)|min(DUB)|min(CLA)|min(MUL)|min(CLO)|min(BEL)|min(MAL)|min(Mo)|min(Yr)|min(Wk)|\n",
      "+---+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+-------+-------+-------+\n",
      "|  1|   10.58|    6.63|    7.62|    4.58|    4.54|    2.88|    8.63|    1.79|    5.83|    5.88|    5.46|   10.88|      1|   1961|      1|\n",
      "|  2|    9.04|    3.54|    7.08|    0.67|    2.29|    0.96|     2.5|    0.58|     0.5|    2.67|    5.25|    5.17|      1|   1961|      2|\n",
      "+---+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+-------+-------+-------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "d2_wk_min_1961 = d2_wk_df.filter(d2_wk_df.Yr.isin(1961)).select(*cols_to_show).dropna().groupBy('Wk').min().orderBy('Wk')\n",
    "d2_wk_min_1961.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+-------+-------+-------+\n",
      "| Wk|max(RPT)|max(VAL)|max(ROS)|max(KIL)|max(SHA)|max(BIR)|max(DUB)|max(CLA)|max(MUL)|max(CLO)|max(BEL)|max(MAL)|max(Mo)|max(Yr)|max(Wk)|\n",
      "+---+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+-------+-------+-------+\n",
      "|  1|    13.5|   14.29|   11.75|    6.67|   12.29|    8.33|   14.29|    9.29|   10.92|   10.46|   16.62|   16.46|      1|   1961|      1|\n",
      "|  2|   19.75|   12.08|    19.5|   10.54|   10.37|    9.46|   15.54|    11.5|   10.37|   14.58|   20.71|   16.92|      1|   1961|      2|\n",
      "+---+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+-------+-------+-------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "d2_wk_max_1961 = d2_wk_df.filter(d2_wk_df.Yr.isin(1961)).select(*cols_to_show).dropna().groupBy('Wk').max().orderBy('Wk')\n",
    "d2_wk_max_1961.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trying to find an easier way to calculate these stats at once"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
